### LLM API 사용하기

#### 1. **환경설정 및 API 호출**

OpenAI API 키를 설정하여 API 호출 준비

```python
%pip install openai
import os
from dotenv import load_dotenv

load_dotenv()  # 현재 경로의 .env 파일을 읽어 시스템 환경변수로 등록
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
```

##### - **API 호출을 위한 초기 설정**

```python
from openai import OpenAI

client = OpenAI(api_key=OPENAI_API_KEY)
```

---

#### 2. **Chat Completion**

Chat Completion: 주어진 메시지에 대해 모델이 자연스러운 대화를 생성하는 기능.

 대화 형식으로 사용자 요청에 대한 답을 생성

```python
response = client.chat.completions.create(
    model="gpt-4.1",
    messages=[
        {"role": "system", "content": "당신은 시니컬하지만 친절한 챗봇입니다."},
        {"role": "user", "content": "더운날 점심으로는 뭘 먹으면 좋을까?"}
    ],
    temperature=1.0,
    max_tokens=2048
)

print(response.choices[0].message.content)
```

---

#### 3. **패턴 1: 페르소나 & Few-Shot (기사 제목 교정)**

페르소나를 설정하고 Few-Shot 학습을 통해 모델에게 특정 작업을 요구하는 방식으로 이는 문맥과 스타일을 모델이 잘 이해하도록 설정

```python
def correct_title(query, temperature=0.3):
    system_instruction = """
    기사들이 송고한 제목을 교정해주세요.
    - 기사의 제목이 명확하고 주제와 잘 맞도록 수정해주세요.
    - 독자의 관심을 끌 수 있도록 간결하고 임팩트 있는 표현을 사용해주세요.
    """
    user_message = f"다음 제목을 교정해주세요: {query}"

    response = client.chat.completions.create(
        model="gpt-4.1",
        messages=[
            {"role": "system", "content": system_instruction},
            {"role": "user", "content": user_message}
        ],
        temperature=temperature
    )
    return response.choices[0].message.content
```

---

#### 4. **구조화된 출력 (Structured Output)**

출력 형식을 구조화하여 더 정돈되고 분석적인 데이터를 생성하는 방법으로 이를 통해 모델은 특정 형식에 맞춰 데이터를 제공

```python
def extract_eng_words(query, temperature=0.5):
    system_instruction = """
    당신은 영어 팝송을 이용해 흥미롭고 이해하기 쉬운 방식으로 영어를 가르치는 선생님입니다.
    - 가사에서 3개 단어를 추출하고, 각 단어의 의미와 유사어를 예시와 함께 제공합니다.
    """
    user_message = f"노래가사: {query}"

    response = client.chat.completions.create(
        model="gpt-4.1",
        messages=[{"role": "system", "content": system_instruction}, {"role": "user", "content": user_message}],
        temperature=temperature,
        response_format="json_object"
    )
    
    return json.loads(response.choices[0].message.content)
```

---

#### 5. **생각의 사슬 (Chain-of-Thought)**

사고 과정을 단계별로 풀어내는 기법으로, 문제를 해결하기 위한 논리적인 흐름을 모델에게 유도하는 방식

```python
def finish_my_refregerator(query, temperature=1.2):
    system_instruction = """
    냉장고에 있는 재료를 활용해 저녁 식사 아이디어를 제안하고, 상세 레시피를 제공합니다.
    """
    user_message = f"냉장고에 있는 재료: {query}"

    response = client.chat.completions.create(
        model="gpt-4.1",
        messages=[{"role": "system", "content": system_instruction}, {"role": "user", "content": user_message}],
        temperature=temperature
    )

    return response.choices[0].message.content
```

---

#### 6. **역할극 & 실전 적용 (면접 질문 생성)**

역할극 기법을 통해 특정 직무에 맞는 면접 질문과 모범 답안을 생성하는 예시로, 실제 상황에 대한 실용적인 적용을 도움

```python
def job_interview(job_posting, temperature=0.5):
    system_instruction = """
    주어진 채용 공고를 바탕으로 예상 면접 질문과 모범 답안을 생성합니다.
    하드 스킬과 소프트 스킬 2개 섹션으로 나누어 질문과 답안을 준비합니다.
    """
    user_message = f"채용 공고: {job_posting}"

    response = client.chat.completions.create(
        model="gpt-4.1",
        messages=[{"role": "system", "content": system_instruction}, {"role": "user", "content": user_message}],
        temperature=temperature
    )

    return response.choices[0].message.content
```

---

### 주요 설정 파라미터

* `temperature`: 응답의 창의성 (0 \~ 2). 높은 값일수록 창의적인 답변이 나오고, 낮은 값은 더 정확하고 일관된 답변을 생성
* `max_tokens`: 응답 최대 토큰 수. API 응답의 길이를 제한
* `top_p`: 사용할 상위 누적 확률. 창의적인 결과를 더 잘 제시하도록 하는 파라미터
* `frequency_penalty`: 토큰 사용 빈도수에 대한 패널티. 동일한 단어의 반복을 방지하는데 사용
* `presence_penalty`: 토큰 재사용에 대한 패널티. 이미 사용된 토큰의 재사용을 억제
