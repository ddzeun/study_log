
## 1. **Uvicorn 사용**

* **정의**: Python ASGI 서버 중 하나로, `FastAPI`와 같은 비동기 프레임워크를 실행할 때 사용.
* **특징**:

  * 개발 환경에서 주로 사용 (간단하고 빠른 실행)
  * `uvicorn main:app --reload` 명령어로 핫 리로드 가능
* **예시 코드**:

  ```python
  if __name__ == "__main__":
      uvicorn.run(app, host="0.0.0.0", port=8000)
  ```

* `RunnableWithMessageHistory` + `InMemoryChatMessageHistory`로 세션별 대화 기록 유지
* `uuid.uuid4()`로 세션 ID 생성 및 관리
* 단점: 서버 재시작 시 메모리에 저장된 대화 내용이 모두 초기화됨

## 2. **Gunicorn in-memory**

* **정의**: 프로덕션 환경에서 Python WSGI/ASGI 앱을 실행하는 멀티 프로세스 서버

* **구성**:

  * `uvicorn.workers.UvicornWorker` 사용 시 ASGI 앱 실행 가능
  * `gunicorn.config.py`로 실행 설정
* **워커(Worker)란?**:

  * Gunicorn은 요청 처리를 위해 여러 **워커 프로세스**를 띄움
  * 기본 계산식: `(CPU 코어 수 × 2) + 1`
  * 각 워커는 **독립적인 프로세스**이므로 메모리를 공유하지 않음
  * 예) 워커 3개 → 세션 저장 딕셔너리(`store = {}`)도 3개가 따로 존재
* **차이점**:

  * Uvicorn은 **단일 프로세스** → 메모리 공유 O
  * Gunicorn은 **멀티 프로세스** → 프로세스 간 메모리 공유 X
    → `store = {}` 방식의 in-memory 저장소는 각 프로세스별로 따로 생성됨

* Gunicorn + in-memory 사용 시 세션 ID 기반 저장이 각 프로세스별로 분리
* 해결 방안: Redis, DB, Vector Store 등 외부 저장소 사용 필요

* Gunicorn + in-memory 사용 시 세션 ID 기반 저장이 각 프로세스별로 분리
* 해결 방안: Redis, DB, Vector Store 등 외부 저장소 사용 필요


## 3. **Gunicorn + Vector Store (Pinecone)**

* **목적**: 멀티 프로세스 환경에서도 대화 기록을 공유하고 유지
* **구성 요소**:

  * **Pinecone Vector Store**: 문서(대화 내용) 저장 및 검색
  * **Namespace**: 세션 ID 별로 독립된 공간 생성 (`conversation_{session_id}`)
  * **Document 저장 방식**:

    * `"System: ..."` / `"Human: ..."` / `"AI: ..."` 형태로 prefix 부여
    * `metadata`에 `created_at`(timestamp) 저장
* **동작 흐름**:

  1. `/init_conversation` → 새로운 UUID 기반 namespace 생성 + 시작 메시지 저장
  2. `/conversation`

     * Human 메시지 Vector Store에 저장
     * Pinecone에서 이전 기록 로드 → `RunnableWithMessageHistory`로 LLM 호출
     * AI 응답 Vector Store에 저장
  3. `/remove_conversation` → namespace 삭제
* **장점**:

  * Gunicorn 멀티 프로세스 환경에서도 대화 이력 공유 가능
  * 서버 재시작 후에도 기록 유지
* **단점**:

  * 외부 API 호출(Pinecone)로 인해 응답 속도가 다소 느릴 수 있음
